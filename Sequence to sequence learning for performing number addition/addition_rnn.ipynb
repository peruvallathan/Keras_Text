{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOOtp6d5gIM"
   },
   "source": [
    "# Sequence to sequence learning for performing number addition\n",
    "\n",
    "**Author:** [Smerity](https://twitter.com/Smerity) and others<br>\n",
    "**Date created:** 2015/08/17<br>\n",
    "**Last modified:** 2020/04/17<br>\n",
    "**Description:** A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo5sqGeb5gIN"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Input: \"535+61\"\n",
    "- Output: \"596\"\n",
    "\n",
    "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
    " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
    "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf).\n",
    "\n",
    "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
    " source and target for this problem.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70mlaoHL5gIN"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eHyfRnpl5gIO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 15:24:35.716125: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 15:24:35.938106: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-06 15:24:36.798852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-09-06 15:24:36.798903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-09-06 15:24:36.798908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/zlabs-hwa-01/anaconda3/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/zlabs-hwa-01/anaconda3/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/zlabs-hwa-01/anaconda3/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_18SourceLocationImplE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/zlabs-hwa-01/anaconda3/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/zlabs-hwa-01/anaconda3/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/zlabs-hwa-01/anaconda3/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN3tsl13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8stkonZ5gIO"
   },
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fQgRv7r_5gIO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYPrn1nH5gIP"
   },
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7iHg8mtS5gIP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1984538/1046822725.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
      "/tmp/ipykernel_1984538/1046822725.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ptQsRcl5gIP"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sfEHuX4I5gIQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 15:24:45.071371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-09-06 15:24:45.071619: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 515.105.1 does not match DSO version 530.30.2 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhwWPg_45gIQ"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJyhOgZN5gIQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 22s 12ms/step - loss: 1.7456 - accuracy: 0.3596 - val_loss: 1.5378 - val_accuracy: 0.4215\n",
      "1/1 [==============================] - 1s 908ms/step\n",
      "Q 33+86   T 119  ☒ 148 \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 350+750 T 1100 ☒ 101 \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 11+748  T 759  ☒ 268 \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 366+56  T 422  ☒ 668 \n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 187+450 T 637  ☒ 695 \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 17+35   T 52   ☒ 11  \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 1+409   T 410  ☒ 140 \n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 39+96   T 135  ☒ 105 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 127+50  T 177  ☒ 268 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 12+27   T 39   ☒ 12  \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3532 - accuracy: 0.4924 - val_loss: 1.1858 - val_accuracy: 0.5628\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 14+367  T 381  ☒ 384 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 863+57  T 920  ☒ 921 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 627+455 T 1082 ☒ 1114\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 709+131 T 840  ☒ 854 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 299+69  T 368  ☒ 325 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 474+783 T 1257 ☒ 1244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 18+25   T 43   ☒ 25  \n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Q 366+3   T 369  ☒ 365 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 15+477  T 492  ☒ 488 \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 987+388 T 1375 ☒ 1344\n",
      "\n",
      "Iteration 3\n",
      "  84/1407 [>.............................] - ETA: 15s - loss: 1.1932 - accuracy: 0.5522"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOJsox2Y5gIQ"
   },
   "source": [
    "You'll get to 99+% validation accuracy after ~30 epochs.\n",
    "\n",
    "Example available on HuggingFace.\n",
    "\n",
    "| Trained Model | Demo |\n",
    "| :--: | :--: |\n",
    "| [![Generic badge](https://img.shields.io/badge/🤗%20Model-Addition%20LSTM-black.svg)](https://huggingface.co/keras-io/addition-lstm) | [![Generic badge](https://img.shields.io/badge/🤗%20Spaces-Addition%20LSTM-black.svg)](https://huggingface.co/spaces/keras-io/addition-lstm) |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "addition_rnn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
